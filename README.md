# ğŸš€ AI-Powered Marketing Ad Generator

A fine-tuned GPT-2 model for generating personalized Facebook ads with GPU acceleration support.

## ğŸ“‹ Table of Contents

- [Dependencies & Installation](#dependencies--installation)
- [GPU Setup](#gpu-setup)
- [Complete Workflow](#complete-workflow)
- [Usage](#usage)
- [Project Structure](#project-structure)

## ğŸ”§ Dependencies & Installation

### 1. System Requirements

- **Python**: 3.8+
- **GPU**: NVIDIA GPU with CUDA support (recommended)
- **CUDA**: 11.8+ or 12.0+
- **Memory**: 8GB+ GPU memory recommended

### 2. Install Dependencies

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment (Windows)
venv\Scripts\activate

# Install PyTorch with CUDA support (choose your CUDA version)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install core dependencies
pip install -r requirements.txt
```

### 3. Required Dependencies (`requirements.txt`)

```txt
# Core ML Libraries
torch>=2.0.0
transformers>=4.30.0
datasets>=2.12.0
accelerate>=0.20.0

# NLP Processing
spacy>=3.6.0
sentence-transformers>=2.2.0
textblob>=0.17.1
langdetect>=1.0.9

# Data Processing
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0

# Web Interface
streamlit>=1.24.0

# Utilities
tqdm>=4.65.0
matplotlib>=3.7.0
seaborn>=0.12.0

# spaCy Model (install separately)
# python -m spacy download en_core_web_sm
```

### 4. Install spaCy Model

```bash
# Install English model for spaCy
python -m spacy download en_core_web_sm

# For GPU acceleration (optional)
pip install spacy[cuda118]  # or cuda120
python -m spacy download en_core_web_trf
```

## âš¡ GPU Setup

### 1. Enable GPU Acceleration (Run Once)

```bash
python gpu_accelerator.py
```

## ğŸ”„ Complete Workflow

Follow these steps in order to train the model

### Step 1: Data Preparation

```bash
# Generate enhanced dataset with embeddings
python scripts\generate_dataset.py

# Apply NLP preprocessing and feature extraction
python scripts\nlp_preprocessing.py

# Generate embeddings for clustering
python scripts\generate_embeddings.py
```

### Step 2: Create Training Data

```bash
# Create prompts for fine-tuning
python scripts\create_prompts.py
```

### Step 3: Fine-tune Model

```bash
# Train the GPT-2 model on your data
python scripts\train_finetune.py
```

### Step 4: Test Model

```bash
# Test the fine-tuned model
python test_model.py

# Or test with custom generation
python generate_ad_text.py



### Model Paths

- **Fine-tuned model**: `./models/fine_tuned_gpt2_clustered/`
- **Checkpoints**: `./models/checkpoint-*/`
- **Data**: `./data/`

## ğŸ“ Project Structure

```

marketing_ad_generator/
â”œâ”€â”€ ğŸ“„ README.md # This file
â”œâ”€â”€ ğŸ“„ requirements.txt # Dependencies
â”œâ”€â”€ ğŸ“„ .gitignore # Git ignore rules
â”œâ”€â”€ ğŸš€ gpu_accelerator.py # GPU setup script
â”œâ”€â”€ ğŸ§ª test_model.py # Model testing
â”œâ”€â”€ ğŸ“ generate_ad_text.py # Ad generation script
â”‚
â”œâ”€â”€ ğŸ“± app/
â”‚ â””â”€â”€ app.py # Streamlit web interface
â”‚
â”œâ”€â”€ ğŸ“Š data/
â”‚ â”œâ”€â”€ amazon_ads_dataset.csv # Raw dataset
â”‚ â”œâ”€â”€ enhanced_amazon_ads.csv # Processed dataset
â”‚ â”œâ”€â”€ amazon_ads_with_clusters.json # Clustered data
â”‚ â””â”€â”€ train_data_clustered_prompts.jsonl # Training data
â”‚
â”œâ”€â”€ ğŸ¤– models/
â”‚ â”œâ”€â”€ fine_tuned_gpt2_clustered/ # Final trained model
â”‚ â””â”€â”€ checkpoint-\*/ # Training checkpoints
â”‚
â”œâ”€â”€ ğŸ“œ scripts/
â”‚ â”œâ”€â”€ generate_dataset.py # Data generation
â”‚ â”œâ”€â”€ nlp_preprocessing.py # Text processing
â”‚ â”œâ”€â”€ generate_embeddings.py # Embedding creation
â”‚ â”œâ”€â”€ create_prompts.py # Training prompt creation
â”‚ â””â”€â”€ train_finetune.py # Model training
â”‚
â””â”€â”€ ğŸ““ notebooks/ # Jupyter notebooks (optional)

```

```
